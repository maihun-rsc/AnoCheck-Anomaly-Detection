{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Metadata columns: ['video_id', 'category', 'label', 'features_path', 'frames_dir', 'frame_count', 'mean_motion', 'max_motion', 'std_motion']\n",
      "📊 Valid videos: 199/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 199/199 [2:21:18<00:00, 42.61s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved enhanced features for 199 videos to /Users/Video anomaly/data/processed/metadata/enhanced_features.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Base directory (adjust if needed)\n",
    "PROJECT_ROOT = Path(\"/Users/Video anomaly\")  # Update to your actual root\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "RAW_VIDEOS_DIR = PROJECT_ROOT / \"data\" / \"raw_videos\"\n",
    "\n",
    "# Load metadata\n",
    "metadata_path = PROCESSED_DIR / \"metadata\" / \"video_metadata.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(metadata_path)\n",
    "    print(\"🔍 Metadata columns:\", df.columns.tolist())\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Metadata file not found at {metadata_path}\")\n",
    "    exit()\n",
    "\n",
    "# Fix features path to absolute\n",
    "df['features_path'] = df['features_path'].apply(lambda x: str(PROCESSED_DIR / x))\n",
    "\n",
    "# Build absolute video paths using video_id and category\n",
    "df['video_path_abs'] = df.apply(\n",
    "    lambda row: str(RAW_VIDEOS_DIR / row['category'] / f\"{row['video_id']}.mp4\"),  # Assuming .mp4, adjust extension if needed\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Verify file existence\n",
    "df['video_exists'] = df['video_path_abs'].apply(os.path.exists)\n",
    "df['features_exists'] = df['features_path'].apply(os.path.exists)\n",
    "valid_df = df[df['video_exists'] & df['features_exists']].copy()\n",
    "print(f\"📊 Valid videos: {len(valid_df)}/{len(df)}\")\n",
    "\n",
    "if len(valid_df) < len(df):\n",
    "    print(\"⚠️ Missing files sample:\")\n",
    "    print(df[~df.index.isin(valid_df.index)][['video_id', 'video_path_abs', 'features_path']].head())\n",
    "\n",
    "# Optical flow calculation\n",
    "def calc_optical_flow(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"❌ Cannot open: {video_path}\")\n",
    "        return None\n",
    "    prev_frame = None\n",
    "    flow_magnitudes = []\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        if prev_frame is not None:\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_frame, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            magnitude = np.sqrt(flow[..., 0]**2 + flow[..., 1]**2)\n",
    "            flow_magnitudes.append(np.mean(magnitude))\n",
    "        prev_frame = gray\n",
    "    \n",
    "    cap.release()\n",
    "    return {\n",
    "        'mean_flow': np.mean(flow_magnitudes) if flow_magnitudes else 0,\n",
    "        'max_flow': np.max(flow_magnitudes) if flow_magnitudes else 0\n",
    "    }\n",
    "\n",
    "# Process videos\n",
    "enhanced_data = []\n",
    "for _, row in tqdm(valid_df.iterrows(), total=len(valid_df), desc=\"Processing\"):\n",
    "    try:\n",
    "        # Load existing features\n",
    "        features = np.load(row['features_path'], allow_pickle=True).item()\n",
    "        # Calculate optical flow\n",
    "        flow_features = calc_optical_flow(row['video_path_abs'])\n",
    "        if flow_features:\n",
    "            enhanced_data.append({\n",
    "                'video_id': row['video_id'],\n",
    "                'label': row['label'],\n",
    "                **features,\n",
    "                **flow_features\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed {row['video_id']}: {str(e)}\")\n",
    "\n",
    "# Save enhanced features\n",
    "if enhanced_data:\n",
    "    enhanced_df = pd.DataFrame(enhanced_data)\n",
    "    output_path = PROCESSED_DIR / \"metadata\" / \"enhanced_features.csv\"\n",
    "    enhanced_df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Saved enhanced features for {len(enhanced_data)} videos to {output_path}\")\n",
    "else:\n",
    "    print(\"❌ No videos processed. Check paths and files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
